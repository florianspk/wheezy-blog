---
title: "âš¡ Argo Workflows : Transforme tes jobs Kubernetes en pipelines !"
date: 2025-09-29
summary: "Fini les scripts bash dispersÃ©s ! Avec Argo Workflows, orchestrez des pipelines complexes directement dans Kubernetes."
tags: ["Kubernetes", "GitOps", "DevOps", "Argo", "Workflows"]
categories: ["Automation"]
featuredImage: "featured.png"
---

# ğŸ’¥ STOP aux scripts bash ingÃ©rables

## ğŸ˜¤ Le cauchemar quotidien du DevOps

**8h du matin** : "Je lance mon script de dÃ©ploiement..."

```bash
#!/bin/bash
./build.sh && ./test.sh && ./push.sh && ./notify-slack.sh
# ğŸ¤ EspÃ©rons que tout se passe bien...
```

**8h05** : Le script plante Ã  l'Ã©tape 3 sur 47 ğŸ’€
**8h30** : Tu rÃ©alises que tu dois tout relancer depuis le dÃ©but.
**9h00** : CafÃ© froid, morale en berne â˜•

## ğŸ¯ Argo Workflows : L'orchestrateur Kubernetes

Avec **Argo Workflows**, vous pouvez :
- âœ… **Visualiser** vos pipelines en temps rÃ©el
- âœ… **Relancer** uniquement l'Ã©tape qui a Ã©chouÃ©
- âœ… **ExÃ©cuter en parallÃ¨le** pour gagner du temps
- âœ… **Monitorer** chaque Ã©tape individuellement
- âœ… **GÃ©rer les ressources dynamiquement**
- âœ… **DÃ©boguer** facilement grÃ¢ce Ã  des logs clairs

Tout est **dÃ©claratif** (YAML), versionnÃ© dans Git et s'exÃ©cute **nativement sur Kubernetes**. ğŸš€

---

# ğŸ§  Architecture d'Argo Workflows

## Les composants clÃ©s

```
ğŸ“œ WorkflowTemplate  â†’  ğŸ¬ Workflow  â†’  ğŸƒâ€â™‚ï¸ Pods  â†’  âœ… RÃ©sultats
```

| **Composant** | **RÃ´le** | **Exemple** |
|---------------|----------|-------------|
| ğŸ¯ **Workflow** | Pipeline en cours d'exÃ©cution | CI/CD en action |
| ğŸ“‹ **WorkflowTemplate** | ModÃ¨le rÃ©utilisable | "Build & Deploy" |
| â° **CronWorkflow** | Planification automatique | Backup chaque nuit |
| ğŸ‘‘ **WorkflowController** | Orchestrateur global | GÃ¨re et supervise |

## Types de workflows

<div style="display: flex; gap: 20px; justify-content: space-around; align-items: flex-start; flex-wrap: wrap;">

<div style="flex: 1; min-width: 300px; text-align: center;">

### Workflow simple
{{< mermaid >}}
flowchart TD
    A[Start] --> B[Step 1 : Extract data]
    B --> C[Step 2 : Transform data]
    C --> D[Step 3 : Load to Database]
    D --> E[End]
{{< /mermaid >}}

</div>

<div style="flex: 1; min-width: 300px; text-align: center;">

### Workflow DAG
{{< mermaid >}}
flowchart TD
    A[Start] --> B[Step 1 : Fetch raw data]
    B --> C[Step 2A : Clean data]
    B --> D[Step 2B : Generate metadata]
    C --> E[Step 3 : Aggregate & validate]
    D --> E
    E --> F[Step 4 : Load to production DB]
    F --> G[End]
{{< /mermaid >}}

</div>

</div>

---

# ğŸ› ï¸ Installation rapide

## 1. DÃ©ploiement du contrÃ´leur et de l'UI

```bash
kubectl create namespace argo-workflows
kubectl apply -n argo-workflows -f https://raw.githubusercontent.com/argoproj/argo-workflows/stable/manifests/quick-start-minimal.yaml
kubectl get pods -n argo-workflows
```

Vous devriez voir :
```
workflow-controller-xxx   Running
argo-server-xxx           Running
```

## 2. Installer la CLI Argo

```bash
# Linux
curl -sLO https://github.com/argoproj/argo-workflows/releases/latest/download/argo-linux-amd64.gz
gunzip argo-linux-amd64.gz
chmod +x argo-linux-amd64
sudo mv argo-linux-amd64 /usr/local/bin/argo

# macOS
brew install argo
```

VÃ©rification :
```bash
argo version
```

---

# ğŸ¬ DÃ©monstration : pipeline de donnÃ©es

## Objectif

CrÃ©er un pipeline qui :
1. ğŸ“¥ RÃ©cupÃ¨re des donnÃ©es
2. ğŸ§¹ Les nettoie et gÃ©nÃ¨re des mÃ©tadonnÃ©es **en parallÃ¨le**
3. ğŸ”— AgrÃ¨ge le tout
4. ğŸš€ DÃ©ploie le rÃ©sultat en production

## WorkflowTemplate

```yaml
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: data-pipeline
  namespace: argo-workflows
spec:
  entrypoint: main
  templates:
  - name: main
    dag:
      tasks:
      - name: fetch
        template: fetch-data
      - name: clean
        dependencies: [fetch]
        template: clean-data
      - name: generate-metadata
        dependencies: [fetch]
        template: metadata-generator
      - name: aggregate
        dependencies: [clean, generate-metadata]
        template: aggregator
      - name: deploy
        dependencies: [aggregate]
        template: production-deploy

  - name: fetch-data
    container:
      image: curlimages/curl:8.4.0
      command: ["sh", "-c"]
      args: ["echo 'Fetching data...' && sleep 2"]

  - name: clean-data
    container:
      image: alpine:3.20
      command: ["sh", "-c"]
      args: ["echo 'Cleaning data...' && sleep 1"]

  - name: metadata-generator
    container:
      image: alpine:3.20
      command: ["sh", "-c"]
      args: ["echo 'Generating metadata...' && sleep 1"]

  - name: aggregator
    container:
      image: alpine:3.20
      command: ["sh", "-c"]
      args: ["echo 'Aggregating results...' && sleep 1"]

  - name: production-deploy
    container:
      image: alpine:3.20
      command: ["sh", "-c"]
      args: ["echo 'Deploying to production ğŸš€'"]
```

---

# ğŸš¦ FonctionnalitÃ©s clÃ©s

## Retry automatique
```yaml
retryStrategy:
  limit: 3
  backoff:
    duration: "30s"
    factor: 2
```

## Conditions intelligentes + parameters

Il est possible de passer des parameters de step en step, et il est possible de faire des conditions de lancement de step :

```yaml
- name: deploy-prod
  when: "{{workflow.parameters.env}} == 'production'"
  template: production-step
```

## Artifacts avec S3

Les Artifacts sont un concept clÃ©s dans Argo Workflow c'est ce qui va vous donner la possibilitÃ© de transmettre a l'Ã©tape d'aprÃ©s un fichier/dossier ou bien de le dÃ©poser dans un registry a la fin

```yaml
outputs:
  artifacts:
  - name: report
    path: /tmp/output
    s3:
      bucket: my-artifacts
      key: "{{workflow.name}}/report.tar.gz"
```

---

# â° CronWorkflows : automatisation planifiÃ©e

```yaml
apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: nightly-backup
  namespace: argo-workflows
spec:
  schedule: "0 2 * * *"  # Tous les jours Ã  2h
  workflowSpec:
    entrypoint: backup
    templates:
    - name: backup
      container:
        image: postgres:15
        command: ["sh", "-c"]
        args: ["pg_dump $DB_URL > /tmp/backup.sql"]
        env:
        - name: DB_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
```

---

# ğŸ–¥ï¸ Interface graphique

```bash
kubectl -n argo-workflows port-forward svc/argo-server 2746:2746
```

Ouvrez [http://localhost:2746](http://localhost:2746) pour :
- ğŸ“Š **Visualiser vos workflows**
- ğŸ” **Consulter les logs**
- ğŸ”„ **Relancer ou annuler des workflows**
- ğŸ—‚ï¸ **Explorer les artifacts**

---

# ğŸ† Bonnes pratiques

1. **Utiliser des WorkflowTemplates** pour la rÃ©utilisabilitÃ©.
2. **SÃ©parer vos workflows par namespace** pour l'isolation.
3. **DÃ©finir des Resource Requests/Limits** pour chaque Ã©tape.
4. **SÃ©curiser avec des ServiceAccounts dÃ©diÃ©s**.
5. **Surveiller via Prometheus/Grafana** pour dÃ©tecter les anomalies.

---

# ğŸ”— Ressources utiles

- [Documentation Argo Workflows](https://argoproj.github.io/argo-workflows/)
- [Exemples officiels](https://github.com/argoproj/argo-workflows/tree/master/examples)
- [Argo Community Slack](https://argoproj.github.io/community/join-slack)

---

Avec Argo Workflows, transformez vos scripts Ã©parpillÃ©s en pipelines robustes, scalables et traÃ§ables directement dans Kubernetes. ğŸš€
