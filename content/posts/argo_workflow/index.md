---
title: "Argo Workflows : orchestrer vos jobs Kubernetes comme un pro"
date: 2025-09-19
summary: "Introduction compl√®te √† Argo Workflows avec un exemple simple et reproductible"
tags: ["Kubernetes", "GitOps", "DevOps", "Argo"]
categories: ["Automation"]
featuredImage: "featured.png"
---

# Introduction

## üéØ Pourquoi Argo Workflows ?

Dans le monde Kubernetes, automatiser des processus complexes est un v√©ritable d√©fi.
Que ce soit pour :
- Des **pipelines CI/CD**
- Des **jobs de traitement de donn√©es**
- Du **Machine Learning**
- Ou la **migration d'applications legacy**

On a besoin d'une solution capable de **d√©finir, planifier et ex√©cuter des workflows complexes** directement dans Kubernetes.

C'est exactement ce que fait **Argo Workflows**.
C'est un **orchestrateur Kubernetes-native**, con√ßu pour d√©composer vos jobs en **√©tapes (steps)**, connect√©es entre elles, le tout d√©crit en YAML.

En d'autres termes :
- üìù D√©finition d√©clarative ‚Üí 100% GitOps-friendly
- ‚ö° Scalabilit√© native gr√¢ce √† Kubernetes
- üîó Int√©gration parfaite avec le reste de la suite Argo (Events, CD)

---

## üß© Architecture d'Argo Workflows

Argo Workflows s'appuie sur plusieurs CRDs Kubernetes :

| **Composant**       | **R√¥le** |
|---------------------|----------|
| **Workflow**        | La ressource principale : d√©crit le pipeline √† ex√©cuter |
| **WorkflowTemplate**| Template r√©utilisable de workflow |
| **CronWorkflow**    | Pour ex√©cuter un workflow selon un horaire |
| **WorkflowController** | Le contr√¥leur qui orchestre l'ex√©cution des workflows |

üí° **Concept cl√©** : chaque √©tape d'un workflow est ex√©cut√©e dans un **Pod Kubernetes**, ce qui permet une isolation forte et une scalabilit√© parfaite.


<div style="display: flex; gap: 20px; justify-content: space-around; align-items: flex-start; flex-wrap: wrap;">

<div style="flex: 1; min-width: 300px; text-align: center;">

### Workflow simple
{{< mermaid >}}
flowchart TD
    A[Start] --> B[Step 1 : Extract data]
    B --> C[Step 2 : Transform data]
    C --> D[Step 3 : Load to Database]
    D --> E[End]
{{< /mermaid >}}

</div>

<div style="flex: 1; min-width: 300px; text-align: center;">

### Workflow DAG
{{< mermaid >}}
flowchart TD
    A[Start] --> B[Step 1 : Fetch raw data]
    B --> C[Step 2A : Clean data]
    B --> D[Step 2B : Generate metadata]
    C --> E[Step 3 : Aggregate & validate]
    D --> E
    E --> F[Step 4 : Load to production DB]
    F --> G[End]
{{< /mermaid >}}

</div>

</div>






---

# ‚öôÔ∏è Installation

> **Pr√©-requis** : un cluster Kubernetes fonctionnel et `kubectl`.

1. **Cr√©er un namespace d√©di√©**
{{< highlight bash >}}
kubectl create namespace argo-workflows
{{< /highlight >}}


2. **Installer Argo Workflows**
{{< highlight bash >}}
kubectl apply -n argo-workflows -f https://raw.githubusercontent.com/argoproj/argo-workflows/stable/manifests/quick-start-minimal.yaml
{{< /highlight >}}


3. **V√©rifier que tout est OK**
{{< highlight bash >}}
kubectl get pods -n argo-workflows
{{< /highlight >}}


Vous devriez voir :
```
workflow-controller-xxxx    Running
argo-server-xxxx            Running
```

---

# üé¨ Exemple live : workflow basique

Objectif de la d√©mo :
- D√©finir un workflow qui ex√©cute **deux √©tapes successives** :
  1. Afficher "Hello"
  2. Afficher "World"

---

## Cr√©er le Workflow

{{< highlight yaml >}}
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: data-pipeline-dag-
spec:
  entrypoint: data-pipeline-dag
  templates:
  - name: data-pipeline-dag
    dag:
      tasks:
      - name: fetch-data
        template: fetch-data

      - name: clean-data
        dependencies: [fetch-data]
        template: clean-data

      - name: generate-metadata
        dependencies: [fetch-data]
        template: generate-metadata

      - name: aggregate-validate
        dependencies: [clean-data, generate-metadata]
        template: aggregate-validate

      - name: load-production
        dependencies: [aggregate-validate]
        template: load-production

  # --- Templates (containers ex√©cut√©s) ---
  - name: fetch-data
    container:
      image: alpine:3.20
      command: [sh, -c]
      args: ["echo 'üì• Fetching raw data...' && sleep 2"]

  - name: clean-data
    container:
      image: alpine:3.20
      command: [sh, -c]
      args: ["echo 'üßπ Cleaning data...' && sleep 3"]

  - name: generate-metadata
    container:
      image: alpine:3.20
      command: [sh, -c]
      args: ["echo 'üìù Generating metadata...' && sleep 2"]

  - name: aggregate-validate
    container:
      image: alpine:3.20
      command: [sh, -c]
      args: ["echo 'üîó Aggregating and validating data...' && sleep 4"]

  - name: load-production
    container:
      image: alpine:3.20
      command: [sh, -c]
      args: ["echo 'üöÄ Loading data to production DB...' && sleep 2"]
{{< /highlight >}}


Appliquer le workflow :
{{< highlight yaml >}}
kubectl create -f data-pipeline-dag.yaml
{{< /highlight >}}


Lister les workflows :
{{< highlight bash >}}
kubectl get wf -n argo-workflows
{{< /highlight >}}


üéâ Votre premier workflow Kubernetes est op√©rationnel !

---

# ‚è∞ D√©clencher un workflow √† intervalles r√©guliers

Argo Workflows propose aussi les **CronWorkflows**, pour planifier l'ex√©cution de workflows.

```yaml
# cron-hello-world.yaml
apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: cron-hello-world
  namespace: argo-workflows
spec:
  schedule: "*/5 * * * *" # toutes les 5 minutes
  workflowSpec:
    entrypoint: main
    templates:
    - name: main
      container:
        image: alpine:3.18
        command: [echo]
        args: ["Hello every 5 minutes!"]
```

Appliquer :
```bash
kubectl apply -f cron-hello-world.yaml
```

V√©rifier le d√©clenchement automatique :
```bash
kubectl get wf -n argo-workflows
```

---

# üåê Interface graphique

Argo Workflows poss√®de une **UI tr√®s intuitive** pour visualiser et suivre vos workflows.

1. **Acc√©der √† l'interface graphique :**
```bash
kubectl -n argo-workflows port-forward svc/argo-server 2746:2746
```

2. **Ouvrir dans votre navigateur :**
[http://localhost:2746](http://localhost:2746)

Vous pourrez y voir :
- L'historique des workflows
- Les logs de chaque √©tape
- La visualisation graphique des d√©pendances

---

# üîó Cas d‚Äôusages avanc√©s

Argo Workflows est extr√™mement flexible.
Quelques id√©es pour aller plus loin :

- **CI/CD GitOps**
  D√©ployer vos applications avec Argo Workflows en compl√©ment d'ArgoCD.

- **Machine Learning (MLOps)**
  Orchestrer des pipelines de training et de d√©ploiement de mod√®les.

- **Traitement de donn√©es**
  Lancer des jobs Spark ou ETL directement dans Kubernetes.

- **Automatisation d'infra**
  G√©n√©rer et appliquer des manifests Kubernetes via Terraform/Helm.

---

# ‚úÖ Conclusion

Argo Workflows est un outil puissant pour orchestrer vos pipelines dans Kubernetes :
- D√©finition **d√©clarative** et versionnable
- Ex√©cution **scalable** gr√¢ce aux Pods
- Int√©gration parfaite avec le reste de l'√©cosyst√®me Argo

Prochaine √©tape ?
- Lier Argo Workflows avec **Argo Events** pour du v√©ritable **event-driven orchestration**
